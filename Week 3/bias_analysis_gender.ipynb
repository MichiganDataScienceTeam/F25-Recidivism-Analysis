{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**MDST FA25 Week 3**\n","\n","Week 3: Complete Exercises 2.1 through 3.7"],"metadata":{"id":"_204kz9tdaM7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jGzMm2kwfLp"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# COMPAS Dataset Error Analysis and Bias in Predictive Models"],"metadata":{"id":"Rbxy44U04ghy"}},{"cell_type":"markdown","source":["##Exercise 1: Loading COMPAS Data\n","Load the dataset that you saved from the previous notebook."],"metadata":{"id":"LNeZoA6C4i22"}},{"cell_type":"code","source":["# Load dataset with read_csv\n"],"metadata":{"id":"xbdpG6OpxS95"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Exercise 2: Confusion Matrix, Contingency Table, and Performance Metrics for Gender\n","Use COMPAS predictions to create a confusion matrix. Calculate accuracy, precision, recall, specificity, and F1 score using actual vs predicted values."],"metadata":{"id":"4OiedWivzxUY"}},{"cell_type":"markdown","source":["####Exercise 2.1:\n","Create a Confusion Matrix. Import the `confusion_matrix` function from the `sklearn.metrics` module.\n","*   Then extract the actual labels (`y_actual`) and the predicted labels (`y_pred`) from your DataFrame.\n","    * `y_actual`: This should be the actual outcome, which tells if a person actually recidivated (`two_year_recid` column).\n","    * `y_pred`: This should be the predicted outcome from the model (`score_binary` column).\n","*   Then plot this using seaborn's heatmap function and matplotlib.pyplot."],"metadata":{"id":"FOXp7oszzz15"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Define actual and predicted values\n","\n","# Create a confusion matrix using the function you've imported\n","\n","# Plotting the confusion matrix using seaborn's heatmap\n","\n","# Show the plot\n"],"metadata":{"id":"Jp-krMVBzu0M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Exercise 2.2:\n","Plot confusion matrices for female defendants and male defendants."],"metadata":{"id":"ZE53DlVf2ALh"}},{"cell_type":"code","source":["# Filter the DataFrame based on sex == (i.e.) 'Male'\n","\n","# Define the actual and predicted labels for those defendents\n","\n","# Create a confusion matrix\n","\n","# Convert the confusion matrix to a DataFrame for labeling\n","\n","# Plot the confusion matrix using Seaborn's heatmap\n"],"metadata":{"id":"4tWeSb7P3VL2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Exercise 2.3:\n","Calculate Performance Metrics. Import functions to calculate accuracy, precision, recall, and F1 score from scikit-learn.\n","*   Calculate the **accuracy** of the model by comparing `y_actual` and `y_pred`.\n","    * Accuracy gives a general overview of the model's performance, indicating how often it correctly predicted recidivism versus non-recidivism.\n","*   Calculate the **precision** and recall to understand the quality of the model’s positive predictions.\n","    * Precision is critical when we want to minimize false positives, for example, when misclassifying someone as high-risk unjustly (which could lead to harsher treatment).\n","    * Recall is important when we want to ensure we identify as many actual positives as possible, such as correctly identifying individuals who are likely to reoffend.\n","* Use the values from the confusion matrix to calculate **specificity** (`True Negative`/(`True Negative` + `False Positive`).\n","    * Specificity tells us how well the model identifies actual non-recidivists, minimizing the risk of wrongly labeling people as high-risk when they are not.\n","* Calculate the **F1 score** for a balanced measure of the model’s performance.\n","    * The F1 score is useful when the balance between precision and recall is crucial. For instance, if false positives and false negatives have serious real-world consequences, this metric helps to assess overall balance.\n","\n","**For specificity: ** Run the cell below to extract values for True Negatives (TN), False Positives (FP), False Negatives (FN), and True Positives (TP) from the confusion matrix defined in Exercise 2.1."],"metadata":{"id":"BL53INn-2C4t"}},{"cell_type":"code","source":["# The confusion matrix is originally a 2x2 array, with the following structure:\n","# [[True Negative (TN), False Positive (FP)],\n","#  [False Negative (FN), True Positive (TP)]]\n","# .ravel() makes it easier to extract these four values (left to right) at once.\n","# Where cm is the name of the confusion matrix (can name it anything)\n","\n","tn, fp, fn, tp = cm.ravel()"],"metadata":{"id":"sez7hlEYeLQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate accuracy\n","\n","# Calculate precision, recall\n","\n","# Calculate specificity\n","\n","# Calculate F1 Score\n"],"metadata":{"id":"cruE03uw2DQU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Exercise 3: Error Distribution Analysis Across Demographics"],"metadata":{"id":"vKgSwJAQ6D_e"}},{"cell_type":"markdown","source":["####Exercise 3.1\n","How much more likely are male defendants to get a false positive than female defendants?\n","\n","How much more likely are female defendants to get a false negative than male defendants?"],"metadata":{"id":"GNeZC0-KQno5"}},{"cell_type":"code","source":["# Calculate the False Positive Rate (FPR) for Male defendants\n","\n","# Calculate the False Positive Rate (FPR) for Female defendants\n","\n","# Calculate how much more likely Male defendants are to get a false positive than Female defendants\n","\n","# Calculate the False Negative Rate (FNR) for Male defendants\n","\n","# Calculate the False Negative Rate (FNR) for Female defendants\n","\n","# Calculate how much more likely Female defendants are to get a false negative than Male defendants\n"],"metadata":{"id":"pqFRFXPeYS7N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Exercise 3.2\n","Use the newly created `'false_positive'` and `'false_negative'` columns to calculate the average false positive and false negative rates for each demographic group.\n","*   Group the data by `'sex'` and calculate the mean of `'false_positive'` and `'false_negative'`."],"metadata":{"id":"MeusiudZ2Q4v"}},{"cell_type":"code","source":["# Calculate false positive and false negative rates by sex\n","\n","# Print the rates to understand the differences\n"],"metadata":{"id":"Gz9N68QE2QuA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Exercise 3.3\n","Use Seaborn's barplot to create a bar chart of the false positive rates by sex.\n"],"metadata":{"id":"dBR5rnZk2TaC"}},{"cell_type":"code","source":["# Calculate the False Positive Rate for each sex\n","# Hint: The mean gives the rate of false positives for each sex.\n","\n"],"metadata":{"id":"d5oNo3LD2Ty7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Exercise 3.4\n","Create a bar chart using Seaborn to visualize false negative rates by sex, similar to how false positive rates were plotted."],"metadata":{"id":"i933Z4vA2VxU"}},{"cell_type":"code","source":["# Calculate the False Negative Rate for each sex\n","# Hint: The mean gives the rate of false negatives for each sex."],"metadata":{"id":"zMWDoA6Y2V_1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Exercise 3.6\n","Calculate accuracy, precision, recall, specificity, and F1 score for 2 chosen groups. What does this tell you?"],"metadata":{"id":"ZdoYiSDz3rsl"}},{"cell_type":"code","source":["# Filter the dataset for Male defendants\n","\n","# Filter the dataset for Female defendants\n","\n","# Define the actual and predicted labels for Male defendants\n","\n","# Define the actual and predicted labels for Female defendants\n","\n","# Create a confusion matrix for Male defendants\n","\n","# Calculate metrics for Male defendants\n","\n","# Create a confusion matrix for Female defendants\n","\n","# Calculate metrics for Female defendants\n"],"metadata":{"id":"qY1IXUNi3reP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Exercise 3.7\n","What if we defined score_binary wrong? Define a new column as 1 if `'score_text'` == 'High' and 0 as everything else (we did this already, use the column you made in the last notebook). Then compare false positives and false negatives across sex with this column.\n","\n"],"metadata":{"id":"B1HcRVrfYzK7"}},{"cell_type":"code","source":[],"metadata":{"id":"8SGiFmfeY1oB"},"execution_count":null,"outputs":[]}]}